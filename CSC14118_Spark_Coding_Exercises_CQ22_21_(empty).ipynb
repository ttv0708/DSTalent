{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttv0708/DSTalent/blob/main/CSC14118_Spark_Coding_Exercises_CQ22_21_(empty).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epfrvqOy0XbK"
      },
      "source": [
        "# Install Java and Spark on Hadoop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf3zOXQkRf0l",
        "outputId": "c8ae4709-4db4-43d6-890e-eab664db983d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,024 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,056 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,340 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,532 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,703 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Fetched 30.6 MB in 4s (7,441 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "# install java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.6/spark-3.5.6-bin-hadoop3.tgz\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.5.6-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Llc1FhGNQ3U5"
      },
      "outputs": [],
      "source": [
        "# set your spark folder to your system path environment.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.6-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfAmwnpt1G5p"
      },
      "source": [
        "# Create a SparkSession in Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ExFt_N8-z2m",
        "outputId": "cabc8b79-cbfc-4f2c-9f43-d3b7fb760cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: findspark in /usr/local/lib/python3.11/dist-packages (2.0.1)\n"
          ]
        }
      ],
      "source": [
        "# start pyspark\n",
        "!pip install findspark\n",
        "import findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZU-oJLNVQl45"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\")\\\n",
        "          .appName(\"Spark APIs Exercises\")\\\n",
        "          .config(\"spark.some.config.option\", \"some-value\")\\\n",
        "          .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chdGpJrATCDO"
      },
      "source": [
        "# Example 1: WordCount with Spark DataFrames and Spark RDDs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91A6eRPJUl_0",
        "outputId": "60835e5d-a726-4484-eb7a-6a3df9a8fd63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CSC14118'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 17 (delta 1), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (17/17), 818.44 KiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "!git clone https://github.com/nnthaofit/CSC14118.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJj_K5siTgAx"
      },
      "source": [
        "### Spark DataFrame-based WordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NACaHF44TG_L",
        "outputId": "705ddc6b-aa21-47eb-979d-141e6a5d592b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+\n",
            "|value                       |\n",
            "+----------------------------+\n",
            "|ppap                        |\n",
            "|i have a pen                |\n",
            "|i have an apple             |\n",
            "|ah apple pen                |\n",
            "|i have a pen                |\n",
            "|i have a pineapple          |\n",
            "|ah pineapple pen            |\n",
            "|ppap pen pineapple apple pen|\n",
            "+----------------------------+\n",
            "\n",
            "+---------+-----+\n",
            "|     word|count|\n",
            "+---------+-----+\n",
            "|      pen|    6|\n",
            "|     have|    4|\n",
            "|        i|    4|\n",
            "|    apple|    3|\n",
            "|pineapple|    3|\n",
            "|        a|    3|\n",
            "|     ppap|    2|\n",
            "|       ah|    2|\n",
            "|       an|    1|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "linesDF = spark.read.text(\"CSC14118/ppap.txt\")\n",
        "linesDF.show(linesDF.count(),truncate = False)\n",
        "\n",
        "from pyspark.sql import functions as f\n",
        "wordsDF = linesDF.withColumn(\"word\", f.explode(f.split(f.col(\"value\"), \" \")))\\\n",
        "    .groupBy(\"word\")\\\n",
        "    .count()\\\n",
        "    .sort(\"count\", ascending = False)\n",
        "wordsDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82hKvCdcTj6g"
      },
      "source": [
        "###RDD-based WordCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONOtAnLxSxYK",
        "outputId": "ceb6f67d-361b-4e85-d4ae-d6fcae4cc234"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('pen', 6),\n",
              " ('i', 4),\n",
              " ('have', 4),\n",
              " ('a', 3),\n",
              " ('apple', 3),\n",
              " ('pineapple', 3),\n",
              " ('ppap', 2),\n",
              " ('ah', 2),\n",
              " ('an', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "linesRdd = spark.sparkContext.textFile(\"CSC14118/ppap.txt\")\n",
        "wordsRdd = linesRdd.flatMap(lambda line: line.split(\" \")) \\\n",
        "    .map(lambda word: (word, 1)) \\\n",
        "    .reduceByKey(lambda a, b: a + b)\\\n",
        "    .sortBy(lambda pair:-1*pair[1])\n",
        "wordsRdd.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Data query with Spark DataFrame"
      ],
      "metadata": {
        "id": "eskNBM_J66UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the example data files from GitHub to Drive\n",
        "!git clone https://github.com/nnthaofit/CSC14118.git"
      ],
      "metadata": {
        "id": "T5YNLLU6656Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ab0f89-4015-469a-e0e3-f3e6f9ba9a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CSC14118' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data file: movies.json"
      ],
      "metadata": {
        "id": "EbUxY_c-69xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"json\").load(\"CSC14118/movies.json\")\n",
        "df.show()"
      ],
      "metadata": {
        "id": "ZMLl4NC4t6_-",
        "outputId": "417692f8-b397-4482-e56e-6892a6f89c85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+--------------------+----+\n",
            "|            cast|              genres|               title|year|\n",
            "+----------------+--------------------+--------------------+----+\n",
            "|              []|                  []|After Dark in Cen...|1900|\n",
            "|              []|                  []|Boarding School G...|1900|\n",
            "|              []|                  []|Buffalo Bill's Wi...|1900|\n",
            "|              []|                  []|              Caught|1900|\n",
            "|              []|                  []|Clowns Spinning Hats|1900|\n",
            "|              []|[Short, Documentary]|Capture of Boer B...|1900|\n",
            "|              []|                  []|The Enchanted Dra...|1900|\n",
            "|   [Paul Boyton]|                  []|   Feeding Sea Lions|1900|\n",
            "|              []|            [Comedy]|How to Make a Fat...|1900|\n",
            "|              []|                  []|     New Life Rescue|1900|\n",
            "|              []|                  []|    New Morning Bath|1900|\n",
            "|              []|                  []|Searching Ruins o...|1900|\n",
            "|              []|                  []|The Tribulations ...|1900|\n",
            "|              []|            [Comedy]|Trouble in Hogan'...|1900|\n",
            "|              []|             [Short]|      Two Old Sparks|1900|\n",
            "|[Ching Ling Foo]|             [Short]|The Wonder, Ching...|1900|\n",
            "|              []|             [Short]|  Watermelon Contest|1900|\n",
            "|              []|                  []|   Acrobats in Cairo|1901|\n",
            "|              []|                  []|  An Affair of Honor|1901|\n",
            "|              []|                  []|Another Job for t...|1901|\n",
            "+----------------+--------------------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1a. Show the schema of DataFrame that stores the movies dataset."
      ],
      "metadata": {
        "id": "HNfJKss_7cG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "rJhoYcqQt8XV",
        "outputId": "cc32bed8-d3e1-4c1e-e046-4cbb1f78f41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- cast: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- genres: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1b. Show the number of distinct movies in the dataset"
      ],
      "metadata": {
        "id": "alyy1VZT7rve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.distinct().count()"
      ],
      "metadata": {
        "id": "u6Irt5YPt955",
        "outputId": "594e677d-0156-4030-9b2b-c65dced9b0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28789"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Count the number of movies released during the years 2012 and 2015 (included)"
      ],
      "metadata": {
        "id": "lbRNx-QU73ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.where((df.year>=2012) & (df.year<=2015)).count()"
      ],
      "metadata": {
        "id": "AQFTKSdYt_9G",
        "outputId": "99d16e1a-2415-430f-bb8b-d488d837ed14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1015"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Show the year in which the number of movies released is highest. One highest year is enough"
      ],
      "metadata": {
        "id": "Wm7NfqXp76Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as f\n",
        "cntMoviesByYear = df.groupBy(\"year\").count().sort(\"count\",ascending=False)\n",
        "cntMoviesByYear.show(1)"
      ],
      "metadata": {
        "id": "H6fj91IzuBcO",
        "outputId": "1e6b0dd6-1203-4634-8e7a-bf73ef9a177a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|1919|  634|\n",
            "+----+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cách ngắn gọn hơn\n",
        "df.groupBy(\"year\").count().orderBy(\"count\", ascending=False).show(1)"
      ],
      "metadata": {
        "id": "1M8a07hzLOCt",
        "outputId": "cf54243c-5fa2-4da0-e6b0-b238a4e3b0ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|1919|  634|\n",
            "+----+-----+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Show the list of movies such that for each film, the number of actors/actresses is at least five, and the number of genres it belongs to is at most two genres."
      ],
      "metadata": {
        "id": "EpfIvw-h8Eep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.filter((f.size(df[\"cast\"])>=5) & (f.size(df[\"genres\"])<=2)).show()"
      ],
      "metadata": {
        "id": "_TD58zTjuEzm",
        "outputId": "e986ae7a-f2d9-4239-a2e7-c364ef2e612c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------------+--------------------+----+\n",
            "|                cast|          genres|               title|year|\n",
            "+--------------------+----------------+--------------------+----+\n",
            "|[Earle Foxe, Alie...|         [Drama]|  A Desperate Chance|1913|\n",
            "|[Charlotte Burton...|         [Drama]|    The Archeologist|1914|\n",
            "|[Charlotte Burton...|         [Drama]|At the Potter's W...|1914|\n",
            "|[Herbert Tracey, ...|        [Comedy]|    Back to the Farm|1914|\n",
            "|[Charlotte Burton...|              []|    The Beggar Child|1914|\n",
            "|[William Garwood,...|              []|       Billy's Rival|1914|\n",
            "|[B. Reeves Eason,...|         [Drama]| Break, Break, Break|1914|\n",
            "|[Charlotte Burton...|              []|       The Butterfly|1914|\n",
            "|[Charlotte Burton...|       [Western]|Calamity Anne's L...|1914|\n",
            "|[Charlie Chaplin,...|        [Comedy]|    The Star Boarder|1914|\n",
            "|[Sydney Ayres, Ja...|              []|A Story of Little...|1914|\n",
            "|[Sydney Ayres, Pe...|              []|The Story of the ...|1914|\n",
            "|[Charlotte Burton...|              []|    This Is th' Life|1914|\n",
            "|[Lon Chaney, Leat...|  [Crime, Drama]|   The Ace of Hearts|1921|\n",
            "|[Madge Kennedy, M...| [Comedy, Drama]|  The Purple Highway|1923|\n",
            "|[Douglas Fairbank...|              []| The Thief of Bagdad|1924|\n",
            "|[Kru, Chantui, Na...|   [Documentary]|Chang: A Drama of...|1927|\n",
            "|[H. B. Warner, An...|         [Drama]|     Sorrell and Son|1927|\n",
            "|[Sam De Grasse, V...|     [Adventure]|The Wreck of the ...|1927|\n",
            "|[Fredric March, O...|[Drama, Romance]|     Anthony Adverse|1936|\n",
            "+--------------------+----------------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Show the **movies** whose names are longest"
      ],
      "metadata": {
        "id": "TG1zzyVb8ND9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_val = df.select(f.length(\"title\")).agg({\"length(title)\":\"max\"}).collect()[0][0]\n",
        "df.where(f.length(\"title\")==max_val).show(truncate=False)"
      ],
      "metadata": {
        "id": "YsBt1ARluGJJ",
        "outputId": "ad31d573-8da5-41ab-96e5-a7d479ec4435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+--------------------------------------------------------------------------------------------------------------+----+\n",
            "|cast|genres|title                                                                                                         |year|\n",
            "+----+------+--------------------------------------------------------------------------------------------------------------+----+\n",
            "|[]  |[]    |Cornell-Columbia-University of Pennsylvania Boat Race at Ithaca, N.Y., Showing Lehigh Valley Observation Train|1901|\n",
            "+----+------+--------------------------------------------------------------------------------------------------------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Show the movies whose name contains the word “fighting” (case-insensitive)."
      ],
      "metadata": {
        "id": "h-UJvT_I8QHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.where(f.lower(\"title\").like(\"%fighting%\")).show()"
      ],
      "metadata": {
        "id": "fvTK-g-AuHnu",
        "outputId": "b56c2f5f-dd01-4bfb-ae49-1e7cd0935918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------------+--------------------+----+\n",
            "|                cast|         genres|               title|year|\n",
            "+--------------------+---------------+--------------------+----+\n",
            "|[Bessie Love, Ann...|[Comedy, Drama]|  A Fighting Colleen|1919|\n",
            "|[Blanche Sweet, R...|      [Western]|     Fighting Cressy|1919|\n",
            "|[Harry T. Morey, ...|        [Drama]|    Fighting Destiny|1919|\n",
            "|[Tom Mix, Teddy S...|      [Western]|   Fighting for Gold|1919|\n",
            "|[Jack Perrin, Hoo...|      [Western]|  The Fighting Heart|1919|\n",
            "|[Art Acord, Mildr...|      [Western]|   The Fighting Line|1919|\n",
            "|[William Duncan, ...|       [Action]|  The Fighting Guide|1922|\n",
            "|[Tom Mix, Patsy R...|      [Western]| The Fighting Streak|1922|\n",
            "|[Richard Barthelm...|   [Historical]|  The Fighting Blade|1923|\n",
            "|[Ernest Torrence,...|       [Comedy]| The Fighting Coward|1924|\n",
            "|[Jack Hoxie, Hele...|      [Western]|       Fighting Fury|1924|\n",
            "|[Pat O'Malley, Ma...|        [Drama]|The Fighting Adve...|1924|\n",
            "|[Fred Thomson, Ha...|      [Western]|    The Fighting Sap|1924|\n",
            "|[Richard Talmadge...|       [Action]|  The Fighting Demon|1925|\n",
            "|[Billy Sullivan, ...|       [Sports]|       Fighting Fate|1925|\n",
            "|[George O'Brien, ...|        [Drama]|  The Fighting Heart|1925|\n",
            "|[Bob Reeves, Lew ...|      [Western]|       Fighting Luck|1925|\n",
            "|[Bill Cody, Jean ...|      [Western]|  The Fighting Smile|1925|\n",
            "|[William Haines, ...|        [Drama]| Fighting the Flames|1925|\n",
            "|[William Fairbank...|       [Action]|      Fighting Youth|1925|\n",
            "+--------------------+---------------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Show the list of distinct genres appearing in the dataset"
      ],
      "metadata": {
        "id": "sZwOdpkG8Wkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.explode(df[\"genres\"]).alias(\"genre\")).select(\"genre\").distinct().show()"
      ],
      "metadata": {
        "id": "e2Bkyz_DuI3-",
        "outputId": "dd738017-eb3a-437f-eae7-dc77007f63d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+\n",
            "|        genre|\n",
            "+-------------+\n",
            "|        Crime|\n",
            "|      Romance|\n",
            "|     Thriller|\n",
            "|      Slasher|\n",
            "|Found Footage|\n",
            "|    Adventure|\n",
            "|         Teen|\n",
            "| Martial Arts|\n",
            "|       Sports|\n",
            "|        Drama|\n",
            "|          War|\n",
            "|  Documentary|\n",
            "|       Family|\n",
            "|      Fantasy|\n",
            "|       Silent|\n",
            "|     Disaster|\n",
            "|        Legal|\n",
            "|      Mystery|\n",
            "| Supernatural|\n",
            "|     Suspense|\n",
            "+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. List all movies in which the actor Harrison Ford has participated."
      ],
      "metadata": {
        "id": "zIS1IRFP8ZVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"actor\",f.explode(df[\"cast\"])).where(f.lower(f.col(\"actor\"))==\"harrison ford\").select(df.columns).show()"
      ],
      "metadata": {
        "id": "Ooe3eFjDuJ8q",
        "outputId": "41fd11fe-c966-4a88-d62d-ba409c818cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------------+--------------------+----+\n",
            "|                cast|           genres|               title|year|\n",
            "+--------------------+-----------------+--------------------+----+\n",
            "|[Constance Talmad...|[Romance, Comedy]|Experimental Marr...|1919|\n",
            "|[Constance Talmad...|         [Comedy]| Happiness a la Mode|1919|\n",
            "|[Constance Talmad...|         [Comedy]|Romance and Arabella|1919|\n",
            "|[Vivian Martin, H...|         [Comedy]|      The Third Kiss|1919|\n",
            "|[Harrison Ford, C...|         [Comedy]|The Veiled Adventure|1919|\n",
            "|[Constance Talmad...|         [Comedy]|          Who Cares?|1919|\n",
            "|[Vivian Martin, H...|          [Drama]|You Never Saw Suc...|1919|\n",
            "|[Norma Talmadge, ...|          [Drama]| The Wonderful Thing|1921|\n",
            "|[Alma Rubens, Har...|        [Mystery]|      Find the Woman|1922|\n",
            "|[Constance Talmad...|          [Drama]| The Primitive Lover|1922|\n",
            "|[Norma Talmadge, ...| [Romance, Drama]|     Smilin' Through|1922|\n",
            "|[Helen Jerome Edd...|          [Drama]|     When Love Comes|1922|\n",
            "|[Marion Davies, H...|     [Historical]| Little Old New York|1923|\n",
            "|[Madge Kennedy, H...|          [Drama]|     Three Miles Out|1924|\n",
            "|[Margaret Livings...|          [Drama]|           The Wheel|1925|\n",
            "|[Marie Prevost, H...|         [Comedy]|       Almost a Lady|1926|\n",
            "|[Harrison Ford, M...|          [Drama]| Hell's Four Hundred|1926|\n",
            "|[Harrison Ford, P...|         [Comedy]|   The Nervous Wreck|1926|\n",
            "|[Marie Prevost, H...|         [Comedy]|  Up in Mabel's Room|1926|\n",
            "|[Vera Reynolds, H...|         [Comedy]|         Golf Widows|1928|\n",
            "+--------------------+-----------------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. List all movies in which the actors/actresses whose names include the word “Lewis“ (case-insensitive) have participated."
      ],
      "metadata": {
        "id": "Gj6gxLvh8cXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.withColumn(\"actor\",f.explode(df[\"cast\"])).where(f.lower(f.col(\"actor\")).like(\"%lewis%\")).select(df.columns).show()"
      ],
      "metadata": {
        "id": "GW8U4Yv1uLGC",
        "outputId": "4e30f1ee-2dac-4740-cd2b-a48812eb153e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+--------------------+----+\n",
            "|                cast|     genres|               title|year|\n",
            "+--------------------+-----------+--------------------+----+\n",
            "|[Charlotte Burton...|         []|       The Butterfly|1914|\n",
            "|[Pearl White, She...|    [Drama]|The Exploits of E...|1914|\n",
            "|[Charlotte Burton...|   [Comedy]| Mein Lieber Katrina|1914|\n",
            "|[Norma Talmadge, ...|    [Drama]|      Going Straight|1916|\n",
            "|[Dorothy Gish, Ra...|    [Drama]|Gretchen the Gree...|1916|\n",
            "|[Ben Lewis, Bessi...|  [Western]|     A Sister of Six|1916|\n",
            "|[Gail Kane, Lewis...|    [Drama]| The Bride's Silence|1917|\n",
            "|    [Mitchell Lewis]|    [Drama]|Nine-Tenths of th...|1918|\n",
            "|[Mitchell Lewis, ...|    [Drama]|The Faith of the ...|1919|\n",
            "|[Mary Pickford, R...|   [Comedy]|         The Hoodlum|1919|\n",
            "|[Mitchell Lewis, ...|    [Drama]|Jacques of the Si...|1919|\n",
            "|[Mitchell Lewis, ...|    [Drama]|The Last of His P...|1919|\n",
            "|[Lewis Stone, Jan...|    [Drama]|        Man's Desire|1919|\n",
            "|[Mary Miles Minte...|   [Comedy]|   Yvonne from Paris|1919|\n",
            "|[Mitchell Lewis, ...|    [Drama]|Nine-Tenths of th...|1919|\n",
            "|[Wedgwood Nowell,...|  [Mystery]|                 813|1920|\n",
            "|[Lewis Sargent, W...|[Adventure]|    Huckleberry Finn|1920|\n",
            "|[Pauline Frederic...|    [Drama]|             Salvage|1921|\n",
            "|[Viola Dana, Ralp...|   [Comedy]|The Five Dollar Baby|1922|\n",
            "|[Estelle Taylor, ...|    [Drama]|    A Fool There Was|1922|\n",
            "+--------------------+-----------+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Show top five actors/actresses that have participated in most movies."
      ],
      "metadata": {
        "id": "s_EhHiV38fXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(f.explode(df[\"cast\"]).alias(\"actor\"), \"title\").groupBy(\"actor\").count().sort(f.col('count'), ascending=False).show(5)"
      ],
      "metadata": {
        "id": "8iHf9EAluOMC",
        "outputId": "585cff8c-88a7-4c48-f124-4244aa3f51a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+\n",
            "|           actor|count|\n",
            "+----------------+-----+\n",
            "|    Harold Lloyd|  190|\n",
            "|     Hoot Gibson|  142|\n",
            "|      John Wayne|  136|\n",
            "|Charles Starrett|  116|\n",
            "|    Bebe Daniels|  103|\n",
            "+----------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 2: RDD-based mainpulation\n",
        "\n",
        "\n",
        "*   The data is already in one ore more RDDs.\n",
        "*   You must not convert RDD to DF or use pure Python code.\n"
      ],
      "metadata": {
        "id": "aHQb93lRHj3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Consider a string s that includes only alphabetical letters and spaces. Check whether s is a palindrome (case-insensitive)."
      ],
      "metadata": {
        "id": "o1F4O-msHoDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Dogma I am God\"\n",
        "rdd = spark.sparkContext.parallelize(s.lower(), 1).filter(lambda letter: letter != ' ')\n",
        "rdd.collect()"
      ],
      "metadata": {
        "id": "sTSEfW6WuQ_e",
        "outputId": "edc97a12-098f-4825-fa80-f2b62f5f0c8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['d', 'o', 'g', 'm', 'a', 'i', 'a', 'm', 'g', 'o', 'd']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_id = spark.sparkContext.parallelize(range(0, rdd.count()), 1)\n",
        "rdd_id.collect()"
      ],
      "metadata": {
        "id": "oKHcYWsxTfW1",
        "outputId": "ef60aeea-b31a-418c-80e8-f408952bb914",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_a = rdd_id.zip(rdd)\n",
        "rdd_a.collect()"
      ],
      "metadata": {
        "id": "Alm-hvJ1Tgic",
        "outputId": "7b2bbab5-4e1d-4c7b-a6d2-54ba4a2f9910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'd'),\n",
              " (1, 'o'),\n",
              " (2, 'g'),\n",
              " (3, 'm'),\n",
              " (4, 'a'),\n",
              " (5, 'i'),\n",
              " (6, 'a'),\n",
              " (7, 'm'),\n",
              " (8, 'g'),\n",
              " (9, 'o'),\n",
              " (10, 'd')]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_b = rdd_a.sortBy(lambda row: row[0]*-1)\n",
        "rdd_b.collect()"
      ],
      "metadata": {
        "id": "IdJUP8_7Tiwd",
        "outputId": "e618c1d9-8082-432d-d7ef-fedb4f205659",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 'd'),\n",
              " (9, 'o'),\n",
              " (8, 'g'),\n",
              " (7, 'm'),\n",
              " (6, 'a'),\n",
              " (5, 'i'),\n",
              " (4, 'a'),\n",
              " (3, 'm'),\n",
              " (2, 'g'),\n",
              " (1, 'o'),\n",
              " (0, 'd')]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_compare = rdd_a.zip(rdd_b)\n",
        "rdd_compare.collect()"
      ],
      "metadata": {
        "id": "3FuWxTLgTlfO",
        "outputId": "43e2de2a-3f06-43b8-8028-9a4b81e1c18e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((0, 'd'), (10, 'd')),\n",
              " ((1, 'o'), (9, 'o')),\n",
              " ((2, 'g'), (8, 'g')),\n",
              " ((3, 'm'), (7, 'm')),\n",
              " ((4, 'a'), (6, 'a')),\n",
              " ((5, 'i'), (5, 'i')),\n",
              " ((6, 'a'), (4, 'a')),\n",
              " ((7, 'm'), (3, 'm')),\n",
              " ((8, 'g'), (2, 'g')),\n",
              " ((9, 'o'), (1, 'o')),\n",
              " ((10, 'd'), (0, 'd'))]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (rdd_compare.filter(lambda row: row[0][1] != row[1][1]).count() == 0):\n",
        "  print(\"Palindrome\")\n",
        "else:\n",
        "  print(\"Not palindrome\")"
      ],
      "metadata": {
        "id": "DVrY7Mg7Tpns",
        "outputId": "5c5ca579-1abe-453b-c33e-891ff30ecbde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palindrome\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Consider a string s that includes only alphabetical letters and spaces. Check whether s is a pangram (case-insensitive)."
      ],
      "metadata": {
        "id": "J6QVU6UWHwYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# s = \"The quick brown fox jumps over the lazy dog\"\n",
        "s = \"The man who passes the sentence should swing the sword\"\n",
        "rdd = spark.sparkContext.parallelize(s.lower(), 1).filter(lambda letter: letter != ' ')\n",
        "rdd.collect()"
      ],
      "metadata": {
        "id": "KT8sz6JduSkB",
        "outputId": "269bb747-79ed-4cc1-d199-6351e8e8e8e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t',\n",
              " 'h',\n",
              " 'e',\n",
              " 'm',\n",
              " 'a',\n",
              " 'n',\n",
              " 'w',\n",
              " 'h',\n",
              " 'o',\n",
              " 'p',\n",
              " 'a',\n",
              " 's',\n",
              " 's',\n",
              " 'e',\n",
              " 's',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 's',\n",
              " 'e',\n",
              " 'n',\n",
              " 't',\n",
              " 'e',\n",
              " 'n',\n",
              " 'c',\n",
              " 'e',\n",
              " 's',\n",
              " 'h',\n",
              " 'o',\n",
              " 'u',\n",
              " 'l',\n",
              " 'd',\n",
              " 's',\n",
              " 'w',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 's',\n",
              " 'w',\n",
              " 'o',\n",
              " 'r',\n",
              " 'd']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if rdd.distinct().count() == 26:\n",
        "  print(\"Pangram\")\n",
        "else:\n",
        "  print(\"Not pangram\")"
      ],
      "metadata": {
        "id": "EsgUvOHzTsyb",
        "outputId": "2798a4b1-9724-489b-9836-8c27a67b8453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not pangram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 3: Frequent patterns and association rules mining"
      ],
      "metadata": {
        "id": "QOoFk6Z2H13m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Load the data file: foodmart.csv\n",
        "\n",
        "\n",
        "*  A record is a tuple of binary values {0, 1}, each of which denotes the presence of an item (1: bought, 0: not bought).\n",
        "\n"
      ],
      "metadata": {
        "id": "uH3ozoTVH6J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nnthaofit/CSC14118.git\n",
        "df = spark.read.csv(\"CSC14118/foodmart.csv\", header=True, inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "4N9eo13QH_Tt",
        "outputId": "2559d490-e6bd-4184-9c02-56d7efe6d416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CSC14118' already exists and is not an empty directory.\n",
            "+------------+---------+-------+--------------+------+---------+----+-------+-------+------------+-----------------+------+------+-----+---------+---------------+-----+--------+------+-------------+------------------+-----------+-------+-----------+--------------+--------+----------+-----------+-----------+----+------+-----------+----------+----+-----------------+---------------+------------+-------------+----------+--------------+-----------------+---+---------+----------+--------------+--------+---------+---------+---+-----+-----+----------+----+----+---------+-------+------------+----+-------+-----------+--------+------------+-----------+-----+-------------+----------------+-----+----------------+-------+---------+------------+-------------+-------------+---------+--------+----+--------+------+------------+-------+---------+------+------------+----+----+----------+------+-------+----------------+-----+----------+----+--------------+-----+------------+----+---------+-------+----+------+\n",
            "|Acetominifen|Anchovies|Aspirin|Auto Magazines|Bagels|Batteries|Beer|Bologna|Candles|Canned Fruit|Canned Vegetables|Cereal|Cheese|Chips|Chocolate|Chocolate Candy|Clams|Cleaners|Coffee|Cold Remedies|Computer Magazines|Conditioner|Cookies|Cooking Oil|Cottage Cheese|Crackers|Deli Meats|Deli Salads|Deodorizers|Dips|Donuts|Dried Fruit|Dried Meat|Eggs|Fashion Magazines|Flavored Drinks|French Fries|Fresh Chicken|Fresh Fish|Frozen Chicken|Frozen Vegetables|Gum|Hamburger|Hard Candy|Home Magazines|Hot Dogs|Ibuprofen|Ice Cream|Jam|Jelly|Juice|Lightbulbs|Maps|Milk|Mouthwash|Muffins|Nasal Sprays|Nuts|Oysters|Pancake Mix|Pancakes|Paper Dishes|Paper Wipes|Pasta|Peanut Butter|Personal Hygiene|Pizza|Plastic Utensils|Popcorn|Popsicles|Pot Cleaners|Pot Scrubbers|Pots and Pans|Preserves|Pretzels|Rice|Sardines|Sauces|Screwdrivers|Shampoo|Shellfish|Shrimp|Sliced Bread|Soda|Soup|Sour Cream|Spices|Sponges|Sports Magazines|Sugar|Sunglasses|Tofu|Toilet Brushes|Tools|Toothbrushes|Tuna|TV Dinner|Waffles|Wine|Yogurt|\n",
            "+------------+---------+-------+--------------+------+---------+----+-------+-------+------------+-----------------+------+------+-----+---------+---------------+-----+--------+------+-------------+------------------+-----------+-------+-----------+--------------+--------+----------+-----------+-----------+----+------+-----------+----------+----+-----------------+---------------+------------+-------------+----------+--------------+-----------------+---+---------+----------+--------------+--------+---------+---------+---+-----+-----+----------+----+----+---------+-------+------------+----+-------+-----------+--------+------------+-----------+-----+-------------+----------------+-----+----------------+-------+---------+------------+-------------+-------------+---------+--------+----+--------+------+------------+-------+---------+------+------------+----+----+----------+------+-------+----------------+-----+----------+----+--------------+-----+------------+----+---------+-------+----+------+\n",
            "|           1|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     1|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             1|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      1|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           1|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     1|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         1|             0|       0|        0|        0|  0|    0|    0|         0|   0|   1|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            1|            0|        0|       0|   1|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     1|            0|                 0|          0|      0|          0|             0|       0|         0|          1|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   1|                0|              0|           0|            0|         0|             0|                0|  1|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   1|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   1|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     1|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          1|         0|   0|                0|              0|           0|            0|         0|             1|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               1|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      1|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   1|        0|      0|           0|   0|      0|          0|       0|           0|          1|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      1|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     1|          1|         0|   0|                0|              0|           0|            0|         0|             1|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          1|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        1|         0|             0|       0|        0|        0|  0|    0|    0|         0|   1|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        1|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     1|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          1|             0|       0|         0|          0|          0|   1|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        1|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        1|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           1|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             1|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            1|         0|             1|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          1|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      1|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     1|          1|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      1|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     1|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         1|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      1|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          1|             0|       0|         0|          0|          0|   0|     0|          0|         0|   1|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    1|            0|               0|    1|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     1|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         1|   0|             0|    1|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              1|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   1|   1|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        1|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   1|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     1|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        1|         1|             0|       0|        0|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            0|               0|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   1|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    0|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        1|        0|  0|    0|    0|         0|   0|   0|        0|      0|           0|   0|      0|          0|       0|           0|          0|    0|            1|               0|    0|               1|      1|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "|           0|        0|      0|             0|     0|        0|   0|      0|      0|           0|                0|     0|     0|    1|        0|              0|    0|       0|     0|            0|                 0|          0|      0|          0|             0|       0|         0|          0|          0|   0|     0|          0|         0|   0|                0|              0|           0|            0|         0|             0|                0|  0|        0|         0|             0|       0|        0|        0|  0|    0|    1|         1|   0|   0|        1|      1|           0|   0|      0|          0|       0|           0|          0|    0|            0|               1|    0|               0|      0|        0|           0|            0|            0|        0|       0|   0|       0|     0|           0|      0|        0|     0|           0|   0|   0|         0|     0|      0|               0|    0|         0|   0|             0|    0|           0|   0|        0|      0|   0|     0|\n",
            "+------------+---------+-------+--------------+------+---------+----+-------+-------+------------+-----------------+------+------+-----+---------+---------------+-----+--------+------+-------------+------------------+-----------+-------+-----------+--------------+--------+----------+-----------+-----------+----+------+-----------+----------+----+-----------------+---------------+------------+-------------+----------+--------------+-----------------+---+---------+----------+--------------+--------+---------+---------+---+-----+-----+----------+----+----+---------+-------+------------+----+-------+-----------+--------+------------+-----------+-----+-------------+----------------+-----+----------------+-------+---------+------------+-------------+-------------+---------+--------+----+--------+------+------------+-------+---------+------+------------+----+----+----------+------+-------+----------------+-----+----------+----+--------------+-----+------------+----+---------+-------+----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Convert the given data to the format required by Spark MLlib FPGrowth."
      ],
      "metadata": {
        "id": "FhDrkKXZH_dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, array, lit, when\n",
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "SryD0vQOuek5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy tên tất cả các cột\n",
        "columns = df.columns"
      ],
      "metadata": {
        "id": "5io2HvOjU3ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chuyển mỗi hàng thành danh sách các mặt hàng có giá trị == 1\n",
        "df_array = df.select(\n",
        "    F.array([\n",
        "        F.when(F.col(col) == 1, F.lit(col)).otherwise(F.lit(None))\n",
        "        for col in columns\n",
        "    ]).alias(\"items\")\n",
        ")\n",
        "df_array.show()"
      ],
      "metadata": {
        "id": "9OQOHAAcUzhS",
        "outputId": "24b24c95-87bb-4925-e5f2-5dc8b2e8ddf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|               items|\n",
            "+--------------------+\n",
            "|[Acetominifen, NU...|\n",
            "|[Acetominifen, NU...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "|[NULL, NULL, NULL...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loại bỏ các NULL trong mảng (chỉ giữ các mục đã mua)\n",
        "df_clean = df_array.selectExpr(\"filter(items, x -> x is not null) as items\")\n",
        "df_clean.show(truncate=False)"
      ],
      "metadata": {
        "id": "Z949OSwLU5vj",
        "outputId": "1bb79fc6-ec5c-4024-9cd8-ad1720fb842e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+\n",
            "|items                                                                |\n",
            "+---------------------------------------------------------------------+\n",
            "|[Acetominifen, Cheese, Home Magazines, Shampoo]                      |\n",
            "|[Acetominifen, Cheese, Hard Candy, Milk, Pot Scrubbers, Rice]        |\n",
            "|[Coffee, Deli Salads]                                                |\n",
            "|[Eggs, Gum, Milk, Soup]                                              |\n",
            "|[Cheese, Dried Fruit, Frozen Chicken, Plastic Utensils]              |\n",
            "|[Shampoo]                                                            |\n",
            "|[Milk, Paper Wipes, Waffles]                                         |\n",
            "|[Donuts, Dried Fruit, Frozen Chicken]                                |\n",
            "|[Cooking Oil, Hamburger, Maps, Popsicles]                            |\n",
            "|[Cheese, Cooking Oil, Dips, Preserves, TV Dinner]                    |\n",
            "|[Nasal Sprays]                                                       |\n",
            "|[Auto Magazines, Fresh Chicken, Frozen Chicken, Pancake Mix, Waffles]|\n",
            "|[Donuts, Dried Fruit, Waffles]                                       |\n",
            "|[Cheese, Lightbulbs, Shampoo]                                        |\n",
            "|[Cooking Oil, Eggs, Pasta, Pizza, Sauces, Sunglasses, Tools]         |\n",
            "|[Flavored Drinks, Soda, Soup, TV Dinner]                             |\n",
            "|[Tuna]                                                               |\n",
            "|[Coffee, Hamburger, Hard Candy, Soda]                                |\n",
            "|[Ibuprofen, Peanut Butter, Plastic Utensils, Popcorn]                |\n",
            "|[Chips, Juice, Lightbulbs, Mouthwash, Muffins, Personal Hygiene]     |\n",
            "+---------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.\tApply Spark MLlib FPGrowth to the formatted data. Mine the set of frequent patterns with the minimum support of 0.1. Mine the set of association rules with the minimum confidence of 0.9."
      ],
      "metadata": {
        "id": "OgVP1hS6IDVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.fpm import FPGrowth"
      ],
      "metadata": {
        "id": "BaAIAGDeugcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo FP-Growth model\n",
        "fpGrowth = FPGrowth(itemsCol=\"items\", minSupport=0.01, minConfidence=0.1)\n",
        "model = fpGrowth.fit(df_clean)"
      ],
      "metadata": {
        "id": "TDrzyUMiWVCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tập mục phổ biến\n",
        "frequent_items = model.freqItemsets\n",
        "frequent_items.sort(\"freq\", ascending=False).show(truncate=False)"
      ],
      "metadata": {
        "id": "H9DQ3FkIWXBx",
        "outputId": "7739cf8e-f2be-48fe-fa61-04ad3749511c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+----+\n",
            "|items              |freq|\n",
            "+-------------------+----+\n",
            "|[Cheese]           |285 |\n",
            "|[Soup]             |280 |\n",
            "|[Dried Fruit]      |256 |\n",
            "|[Cookies]          |238 |\n",
            "|[Wine]             |185 |\n",
            "|[Preserves]        |185 |\n",
            "|[Frozen Vegetables]|173 |\n",
            "|[Canned Vegetables]|172 |\n",
            "|[Nuts]             |170 |\n",
            "|[Paper Wipes]      |164 |\n",
            "|[Milk]             |164 |\n",
            "|[Chocolate Candy]  |152 |\n",
            "|[Chips]            |145 |\n",
            "|[Sliced Bread]     |137 |\n",
            "|[Cooking Oil]      |134 |\n",
            "|[Muffins]          |132 |\n",
            "|[Waffles]          |132 |\n",
            "|[Eggs]             |128 |\n",
            "|[Dips]             |127 |\n",
            "|[Cereal]           |125 |\n",
            "+-------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Luật kết hợp\n",
        "association_rules = model.associationRules\n",
        "association_rules.show(truncate=False)"
      ],
      "metadata": {
        "id": "SmZpzuOlXLfO",
        "outputId": "37dad435-dc70-4ab6-84cf-a0f11147f05c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-------------------+-------------------+------------------+--------------------+\n",
            "|antecedent   |consequent         |confidence         |lift              |support             |\n",
            "+-------------+-------------------+-------------------+------------------+--------------------+\n",
            "|[Dried Fruit]|[Soup]             |0.140625           |1.068247767857143 |0.01692524682651622 |\n",
            "|[Dried Fruit]|[Cheese]           |0.125              |0.9328947368421052|0.015044663845792195|\n",
            "|[Dried Fruit]|[Wine]             |0.109375           |1.2575168918918918|0.013164080865068171|\n",
            "|[Dried Fruit]|[Cookies]          |0.1171875          |1.0473017331932772|0.014104372355430184|\n",
            "|[Milk]       |[Soup]             |0.1524390243902439 |1.1579921602787457|0.011753643629525154|\n",
            "|[Lightbulbs] |[Dried Fruit]      |0.2                |1.6617187500000001|0.011283497884344146|\n",
            "|[Wine]       |[Dried Fruit]      |0.15135135135135136|1.257516891891892 |0.013164080865068171|\n",
            "|[Wine]       |[Soup]             |0.15135135135135136|1.14972972972973  |0.013164080865068171|\n",
            "|[Wine]       |[Cheese]           |0.12972972972972974|0.9681934566145092|0.011283497884344146|\n",
            "|[Popsicles]  |[Cheese]           |0.1774193548387097 |1.3241086587436333|0.010343206393982134|\n",
            "|[Paper Wipes]|[Cheese]           |0.14634146341463414|1.0921694480102695|0.011283497884344146|\n",
            "|[Nuts]       |[Dried Fruit]      |0.12941176470588237|1.075229779411765 |0.010343206393982134|\n",
            "|[Nuts]       |[Preserves]        |0.17058823529411765|1.9613036565977742|0.013634226610249177|\n",
            "|[Nuts]       |[Canned Vegetables]|0.12941176470588237|1.600341997264022 |0.010343206393982134|\n",
            "|[Cooking Oil]|[Cheese]           |0.17164179104477612|1.2809897879025922|0.010813352139163141|\n",
            "|[Pizza]      |[Soup]             |0.18032786885245902|1.3698477751756442|0.010343206393982134|\n",
            "|[Soup]       |[Dried Fruit]      |0.12857142857142856|1.0682477678571427|0.01692524682651622 |\n",
            "|[Soup]       |[Wine]             |0.1                |1.1497297297297298|0.013164080865068171|\n",
            "|[Soup]       |[Canned Vegetables]|0.1                |1.2366279069767443|0.013164080865068171|\n",
            "|[Soup]       |[Cheese]           |0.1392857142857143 |1.0395112781954887|0.018335684062059238|\n",
            "+-------------+-------------------+-------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dự đoán mục tiếp theo có thể mua dựa trên các luật\n",
        "predictions = model.transform(df_clean)\n",
        "predictions.select(\"items\", \"prediction\").show(truncate=False)"
      ],
      "metadata": {
        "id": "7FW_DU0xXSbX",
        "outputId": "90a6e439-89bf-4144-a5f7-ca2caf671c7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
            "|items                                                                |prediction                                                                        |\n",
            "+---------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
            "|[Acetominifen, Cheese, Home Magazines, Shampoo]                      |[Dried Fruit, Preserves, Soup]                                                    |\n",
            "|[Acetominifen, Cheese, Hard Candy, Milk, Pot Scrubbers, Rice]        |[Soup, Dried Fruit, Preserves]                                                    |\n",
            "|[Coffee, Deli Salads]                                                |[]                                                                                |\n",
            "|[Eggs, Gum, Milk, Soup]                                              |[Dried Fruit, Wine, Canned Vegetables, Cheese, Cereal, Cookies, Frozen Vegetables]|\n",
            "|[Cheese, Dried Fruit, Frozen Chicken, Plastic Utensils]              |[Soup, Wine, Cookies, Preserves]                                                  |\n",
            "|[Shampoo]                                                            |[]                                                                                |\n",
            "|[Milk, Paper Wipes, Waffles]                                         |[Soup, Cheese]                                                                    |\n",
            "|[Donuts, Dried Fruit, Frozen Chicken]                                |[Soup, Cheese, Wine, Cookies]                                                     |\n",
            "|[Cooking Oil, Hamburger, Maps, Popsicles]                            |[Cheese]                                                                          |\n",
            "|[Cheese, Cooking Oil, Dips, Preserves, TV Dinner]                    |[Dried Fruit, Soup, Nuts, Cookies]                                                |\n",
            "|[Nasal Sprays]                                                       |[]                                                                                |\n",
            "|[Auto Magazines, Fresh Chicken, Frozen Chicken, Pancake Mix, Waffles]|[Soup]                                                                            |\n",
            "|[Donuts, Dried Fruit, Waffles]                                       |[Soup, Cheese, Wine, Cookies]                                                     |\n",
            "|[Cheese, Lightbulbs, Shampoo]                                        |[Dried Fruit, Preserves, Soup]                                                    |\n",
            "|[Cooking Oil, Eggs, Pasta, Pizza, Sauces, Sunglasses, Tools]         |[Cheese, Soup]                                                                    |\n",
            "|[Flavored Drinks, Soda, Soup, TV Dinner]                             |[Dried Fruit, Wine, Canned Vegetables, Cheese, Cereal, Cookies, Frozen Vegetables]|\n",
            "|[Tuna]                                                               |[]                                                                                |\n",
            "|[Coffee, Hamburger, Hard Candy, Soda]                                |[]                                                                                |\n",
            "|[Ibuprofen, Peanut Butter, Plastic Utensils, Popcorn]                |[]                                                                                |\n",
            "|[Chips, Juice, Lightbulbs, Mouthwash, Muffins, Personal Hygiene]     |[Dried Fruit, Soup, Cheese, Cookies]                                              |\n",
            "+---------------------------------------------------------------------+----------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 4: Classification"
      ],
      "metadata": {
        "id": "pxSuXFXoIHO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data file: mushroom.csv\n",
        "*   The data represents a collection of mushroom species.\n",
        "*   There are 8124 examples, each of which has 22 attributes and it is categorized into either “edible” (e) or “poisonous” (p)\n"
      ],
      "metadata": {
        "id": "mCMfeBzgIL0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"CSC14118/mushrooms.csv\", header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "SXGKh8EPIUJE",
        "outputId": "8a7dd438-4892-4155-c57d-29d6cb1c2b21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
            "|class|cap-shape|cap-surface|cap-color|bruises|odor|gill-attachment|gill-spacing|gill-size|gill-color|stalk-shape|stalk-root|stalk-surface-above-ring|stalk-surface-below-ring|stalk-color-above-ring|stalk-color-below-ring|veil-type|veil-color|ring-number|ring-type|spore-print-color|population|habitat|\n",
            "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
            "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
            "|    e|        x|          s|        y|      t|   a|              f|           c|        b|         k|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
            "|    e|        b|          s|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      m|\n",
            "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      u|\n",
            "|    e|        x|          s|        g|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
            "|    e|        x|          y|        y|      t|   a|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         n|      g|\n",
            "|    e|        b|          s|        w|      t|   a|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         n|      m|\n",
            "|    e|        b|          y|        w|      t|   l|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      m|\n",
            "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         p|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         v|      g|\n",
            "|    e|        b|          s|        y|      t|   a|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      m|\n",
            "|    e|        x|          y|        y|      t|   l|              f|           c|        b|         g|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         n|      g|\n",
            "|    e|        x|          y|        y|      t|   a|              f|           c|        b|         n|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      m|\n",
            "|    e|        b|          s|        y|      t|   a|              f|           c|        b|         w|          e|         c|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      g|\n",
            "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         v|      u|\n",
            "|    e|        x|          f|        n|      f|   n|              f|           w|        b|         n|          t|         e|                       s|                       f|                     w|                     w|        p|         w|          o|        e|                k|         a|      g|\n",
            "|    e|        s|          f|        g|      f|   n|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         y|      u|\n",
            "|    e|        f|          f|        w|      f|   n|              f|           w|        b|         k|          t|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        e|                n|         a|      g|\n",
            "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                k|         s|      g|\n",
            "|    p|        x|          y|        w|      t|   p|              f|           c|        n|         n|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      u|\n",
            "|    p|        x|          s|        n|      t|   p|              f|           c|        n|         k|          e|         e|                       s|                       s|                     w|                     w|        p|         w|          o|        p|                n|         s|      u|\n",
            "+-----+---------+-----------+---------+-------+----+---------------+------------+---------+----------+-----------+----------+------------------------+------------------------+----------------------+----------------------+---------+----------+-----------+---------+-----------------+----------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\tPrepare the train and test sets following the ratio 8:2"
      ],
      "metadata": {
        "id": "JdIdZJ2zIUge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "kAcyo8DJIZou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Fit a decision tree model on the training set, using Spark MLlib DecisionTreeClassifier with default parameters"
      ],
      "metadata": {
        "id": "zbshjQjnIZz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Lấy tên các cột\n",
        "label_col = 'class'  # Tên cột phân loại: 'e' hoặc 'p'\n",
        "feature_cols = [col for col in df.columns if col != label_col]\n",
        "\n",
        "# Mã hóa label\n",
        "label_indexer = StringIndexer(inputCol=label_col, outputCol=\"label\")\n",
        "\n",
        "# Mã hóa các feature dạng chuỗi\n",
        "feature_indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=f\"{col}_index\", handleInvalid=\"keep\")\n",
        "    for col in feature_cols\n",
        "]\n",
        "\n",
        "# Tập hợp các đặc trưng lại thành 1 vector\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"{col}_index\" for col in feature_cols],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Decision Tree\n",
        "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Pipeline\n",
        "dt_pipeline = Pipeline(stages=[label_indexer] + feature_indexers + [assembler, dt])\n",
        "\n",
        "# Huấn luyện\n",
        "dt_model = dt_pipeline.fit(train_data)\n"
      ],
      "metadata": {
        "id": "TNbvDsqIIbNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Fit a random forest model on the training set, using Spark MLlib RandomForestClassification with default parameters"
      ],
      "metadata": {
        "id": "ghWaZW7LIbr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Pipeline\n",
        "rf_pipeline = Pipeline(stages=[label_indexer] + feature_indexers + [assembler, rf])\n",
        "\n",
        "# Huấn luyện\n",
        "rf_model = rf_pipeline.fit(train_data)"
      ],
      "metadata": {
        "id": "jVhzgPw7IcOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluate the two models on the same test set using the following metrics: areaUnderROC and areaUnderPR"
      ],
      "metadata": {
        "id": "TCWbqsk0IoSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Dự đoán trên tập test\n",
        "dt_predictions = dt_model.transform(test_data)\n",
        "rf_predictions = rf_model.transform(test_data)\n",
        "\n",
        "evaluator_roc = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
        "evaluator_pr = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderPR\")\n",
        "\n",
        "# Đánh giá Decision Tree\n",
        "dt_auc = evaluator_roc.evaluate(dt_predictions)\n",
        "dt_pr = evaluator_pr.evaluate(dt_predictions)\n",
        "\n",
        "# Đánh giá Random Forest\n",
        "rf_auc = evaluator_roc.evaluate(rf_predictions)\n",
        "rf_pr = evaluator_pr.evaluate(rf_predictions)\n",
        "\n",
        "print(f\"Decision Tree - AUC: {dt_auc:.4f}, PR: {dt_pr:.4f}\")\n",
        "print(f\"Random Forest - AUC: {rf_auc:.4f}, PR: {rf_pr:.4f}\")"
      ],
      "metadata": {
        "id": "G4YrCL5-IohK",
        "outputId": "5d10442a-9207-4dc5-f0c6-a2c079ee16a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - AUC: 0.9948, PR: 0.9973\n",
            "Random Forest - AUC: 1.0000, PR: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Chain the above steps into a single pipeline"
      ],
      "metadata": {
        "id": "cTJAVAGeIr3a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I3wOtZdWIzsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: Clustering"
      ],
      "metadata": {
        "id": "dn-fgVNlIxZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"MushroomClustering\").getOrCreate()\n",
        "df = spark.read.csv(\"CSC14118/mushrooms.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Xử lý: Mã hóa tất cả cột kiểu chuỗi\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"keep\")\n",
        "    for col in df.columns\n",
        "]\n",
        "\n",
        "# VectorAssembler cho toàn bộ cột đã mã hóa\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"{col}_idx\" for col in df.columns],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(stages=indexers + [assembler])\n",
        "df_transformed = pipeline.fit(df).transform(df)\n"
      ],
      "metadata": {
        "id": "nqGZvNcWIxih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.\tCluster the data by using Spark MLlib KMeans with k = 2, 3, and 5, using Euclidean distance and cosine distance"
      ],
      "metadata": {
        "id": "IdHBhBHqIxqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "def train_kmeans_models(df, ks, distance):\n",
        "    models = {}\n",
        "    for k in ks:\n",
        "        kmeans = KMeans(featuresCol=\"features\", predictionCol=\"prediction\", k=k, distanceMeasure=distance, seed=42)\n",
        "        model = kmeans.fit(df)\n",
        "        models[(k, distance)] = model.transform(df)\n",
        "    return models\n",
        "\n",
        "ks = [2, 3, 5]\n",
        "models_euclidean = train_kmeans_models(df_transformed, ks, \"euclidean\")\n",
        "models_cosine = train_kmeans_models(df_transformed, ks, \"cosine\")"
      ],
      "metadata": {
        "id": "DJV4mX3_IxyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Evaluate each of the above clustering results using silhoutte score. Which configuration yeilds the best clustering?"
      ],
      "metadata": {
        "id": "dBo8pvyOIx5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "evaluator = ClusteringEvaluator(featuresCol=\"features\", predictionCol=\"prediction\", metricName=\"silhouette\")\n",
        "\n",
        "def evaluate_models(models):\n",
        "    scores = {}\n",
        "    for (k, dist), df_clustered in models.items():\n",
        "        score = evaluator.evaluate(df_clustered)\n",
        "        scores[(k, dist)] = score\n",
        "    return scores\n",
        "\n",
        "scores_euclidean = evaluate_models(models_euclidean)\n",
        "scores_cosine = evaluate_models(models_cosine)\n",
        "\n",
        "print(\"Silhouette Scores (Euclidean):\")\n",
        "for key, val in scores_euclidean.items():\n",
        "    print(f\"k={key[0]} → score={val:.4f}\")\n",
        "\n",
        "print(\"\\nSilhouette Scores (Cosine):\")\n",
        "for key, val in scores_cosine.items():\n",
        "    print(f\"k={key[0]} → score={val:.4f}\")"
      ],
      "metadata": {
        "id": "3NekP_ioIyCU",
        "outputId": "badd4904-8828-423d-d17f-88e54995418c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette Scores (Euclidean):\n",
            "k=2 → score=0.2807\n",
            "k=3 → score=0.3782\n",
            "k=5 → score=0.3139\n",
            "\n",
            "Silhouette Scores (Cosine):\n",
            "k=2 → score=0.2758\n",
            "k=3 → score=0.2663\n",
            "k=5 → score=0.3051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Chain the above steps into a single pipeline"
      ],
      "metadata": {
        "id": "GMAMYR1mJDk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def full_pipeline(df, ks, distance):\n",
        "    pipeline = Pipeline(stages=indexers + [assembler])\n",
        "    df_transformed = pipeline.fit(df).transform(df)\n",
        "    models = train_kmeans_models(df_transformed, ks, distance)\n",
        "    scores = evaluate_models(models)\n",
        "    return models, scores\n",
        "\n",
        "models_euclidean, scores_euclidean = full_pipeline(df, ks, \"euclidean\")\n",
        "models_cosine, scores_cosine = full_pipeline(df, ks, \"cosine\")"
      ],
      "metadata": {
        "id": "429A9QeCIsT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. For each clustering result obtained above, count the number of examples that belong to each of the three species."
      ],
      "metadata": {
        "id": "h1ByWgvaJHp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_clusters(models):\n",
        "    for (k, dist), df_clustered in models.items():\n",
        "        print(f\"\\n=== Clusters for k={k}, distance={dist} ===\")\n",
        "        df_clustered.groupBy(\"prediction\").count().orderBy(\"prediction\").show()\n",
        "\n",
        "count_clusters(models_euclidean)\n",
        "count_clusters(models_cosine)"
      ],
      "metadata": {
        "id": "AYyWW4ltJII8",
        "outputId": "a5191a4e-aec8-4b8f-a1ef-8958a59032b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Clusters for k=2, distance=euclidean ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 4745|\n",
            "|         1| 3379|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "=== Clusters for k=3, distance=euclidean ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 4593|\n",
            "|         1| 1258|\n",
            "|         2| 2273|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "=== Clusters for k=5, distance=euclidean ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 1832|\n",
            "|         1| 1860|\n",
            "|         2| 1244|\n",
            "|         3| 1553|\n",
            "|         4| 1635|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "=== Clusters for k=2, distance=cosine ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 2907|\n",
            "|         1| 5217|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "=== Clusters for k=3, distance=cosine ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 2230|\n",
            "|         1| 3431|\n",
            "|         2| 2463|\n",
            "+----------+-----+\n",
            "\n",
            "\n",
            "=== Clusters for k=5, distance=cosine ===\n",
            "+----------+-----+\n",
            "|prediction|count|\n",
            "+----------+-----+\n",
            "|         0| 1624|\n",
            "|         1| 1588|\n",
            "|         2| 1268|\n",
            "|         3| 1730|\n",
            "|         4| 1914|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 6: Network manipulation with Spark GraphFrames"
      ],
      "metadata": {
        "id": "T5epMoIlJOr1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###0. Load the data files: users.txt and followers.txt"
      ],
      "metadata": {
        "id": "I1pTLkFgJUmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nếu bạn dùng notebook trong môi trường Google Colab hoặc Jupyter\n",
        "!pip install graphframes"
      ],
      "metadata": {
        "id": "q1WSkukOJT2P",
        "outputId": "bbac799c-0a7b-40e9-ef85-09726f93b9ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphframes\n",
            "  Downloading graphframes-0.6-py2.py3-none-any.whl.metadata (934 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from graphframes) (2.0.2)\n",
            "Collecting nose (from graphframes)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nose, graphframes\n",
            "Successfully installed graphframes-0.6 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"GraphFramesExample\") \\\n",
        "    .config(\"spark.jars.packages\", \"graphframes:graphframes:0.8.3-spark3.1-s_2.12\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "from graphframes import GraphFrame\n"
      ],
      "metadata": {
        "id": "KABjtm8EZ6_9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đọc file người dùng\n",
        "vertices = spark.read.csv(\"CSC14118/users.txt\", header=True, inferSchema=True)\n",
        "vertices.show()\n",
        "\n",
        "# Đọc file mối quan hệ\n",
        "edges = spark.read.csv(\"CSC14118/followers.txt\", header=True, inferSchema=True)\n",
        "edges.show()"
      ],
      "metadata": {
        "id": "287ChutYaDQc",
        "outputId": "38b71456-c264-426d-8d26-edbd4db046dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+---------------+\n",
            "|  1|  BarackObama|   Barack Obama|\n",
            "+---+-------------+---------------+\n",
            "|  2|     ladygaga|Goddess of Love|\n",
            "|  3|      jeresig|     John Resig|\n",
            "|  4| justinbieber|  Justin Bieber|\n",
            "|  6|matei_zaharia|  Matei Zaharia|\n",
            "|  7|      odersky| Martin Odersky|\n",
            "|  8|      anonsys|           NULL|\n",
            "+---+-------------+---------------+\n",
            "\n",
            "+---+\n",
            "|2 1|\n",
            "+---+\n",
            "|4 1|\n",
            "|1 2|\n",
            "|6 3|\n",
            "|7 3|\n",
            "|7 6|\n",
            "|6 7|\n",
            "|3 7|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1.\tConstruct a graph from the given data to demonstrate a tiny social network\n"
      ],
      "metadata": {
        "id": "zd6XAz-aJYlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = GraphFrame(vertices, edges)\n",
        "g.vertices.show()\n",
        "g.edges.show()"
      ],
      "metadata": {
        "id": "oiEdguBKbZHr",
        "outputId": "20bc87e8-3a63-4777-e068-6896453d521c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyspark/sql/dataframe.py:168: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o60.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-750439395.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, v, e)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sqlContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm_gf_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/graphframes/graphframe.py\u001b[0m in \u001b[0;36m_java_api\u001b[0;34m(jsc)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_java_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mjavaClassName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"org.graphframes.GraphFramePythonAPI\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetContextClassLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjavaClassName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mnewInstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o60.loadClass.\n: java.lang.ClassNotFoundException: org.graphframes.GraphFramePythonAPI\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:387)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418)\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.\tApply Graphs graphPageRank to the network to obtain a ranking list of users in terms of followers"
      ],
      "metadata": {
        "id": "hSV29hkuJct7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SNAmL2y3Jc3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Find connected components on the graph, using Graphs connectedComponents or stronglyConnectedComponents"
      ],
      "metadata": {
        "id": "nIciqOCqJeqH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TqThg_PxJe0v"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}